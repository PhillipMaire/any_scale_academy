{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab15dce2-dda9-46e0-a217-68d7c7ab63e0",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " # Introduction to the Ray AI Libraries: An example of using Ray data, Ray Train, Ray Tune, Ray Serve to implement a XGBoost regression model\n",
    "\n",
    " ¬© 2025, Anyscale. All Rights Reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8c22e0-d2d4-439c-88ef-8e27262a8f5b",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " üíª **Launch Locally**: You can run this notebook locally, but performance will be reduced.\n",
    "\n",
    " üöÄ **Launch on Cloud**: A Ray Cluster with 4 GPUs (Click [here](http://console.anyscale.com/register) to easily start a Ray cluster on Anyscale) is recommended to run this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c371c75-54fc-4740-9c9c-9ea2477c633c",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Let's start with a quick end-to-end example to get a sense of what the Ray AI Libraries can do.\n",
    " <div class=\"alert alert-block alert-info\">\n",
    " <b> Here is the roadmap for this notebook:</b>\n",
    " <ul>\n",
    "     <li>Overview of the Ray AI Libraries</li>\n",
    "     <li>Quick end-to-end example</li>\n",
    "     <ul>\n",
    "       <li>Vanilla XGBoost code</li>\n",
    "       <li>Hyperparameter tuning with Ray Tune</li>\n",
    "       <li>Distributed training with Ray Train</li>\n",
    "       <li>Serving an ensemble model with Ray Serve</li>\n",
    "       <li>Batch inference with Ray Data</li>\n",
    "     </ul>\n",
    " </ul>\n",
    " </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c66b84-f22a-48d9-b537-eee3c50bd817",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77660d9a-0dfb-4c41-a5ab-051927440e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# (Optional): If you get an XGBoostError at import, you might have to `brew install libomp` before importing xgboost again\n",
    "# !brew install libomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4624c4b-6acb-458c-b6e4-60d194915cbb",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " notes: make sure to use the correct RunConfig\n",
    " from ray.train import RunConfig\n",
    " vs\n",
    " from ray.tune import RunConfig\n",
    " for train vs hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b599ae-b639-4b51-8f5d-ca1d5d0db702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import asyncio\n",
    "import fastapi\n",
    "import pandas as pd\n",
    "import requests\n",
    "# macos: If you get an XGBoostError at import, you might have to `brew install libomp` before importing xgboost again\n",
    "import xgboost\n",
    "from pydantic import BaseModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import ray\n",
    "import ray.tune\n",
    "import ray.train\n",
    "from ray.train.xgboost import XGBoostTrainer as RayTrainXGBoostTrainer\n",
    "from ray.train import RunConfig\n",
    "\n",
    "import ray.data\n",
    "import ray.serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dccb23-5066-42ad-968b-5f55efeddcb7",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## 1. Overview of the Ray AI Libraries\n",
    "\n",
    " <img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Ray_AI_Libraries/Ray+AI+Libraries.png\" width=\"700px\" loading=\"lazy\">\n",
    "\n",
    " Built on top of Ray Core, the Ray AI Libraries inherit all the performance and scalability benefits offered by Core while providing a convenient abstraction layer for machine learning. These Python-first native libraries allow ML practitioners to distribute individual workloads, end-to-end applications, and build custom use cases in a unified framework.\n",
    "\n",
    " The Ray AI Libraries bring together an ever-growing ecosystem of integrations with popular machine learning frameworks to create a common interface for development.\n",
    "\n",
    " |<img src=\"https://technical-training-assets.s3.us-west-2.amazonaws.com/Introduction_to_Ray_AIR/e2e_air.png\" width=\"100%\" loading=\"lazy\">|\n",
    " |:-:|\n",
    " |Ray AI Libraries enable end-to-end ML development and provides multiple options for integrating with other tools and libraries from the MLOps ecosystem.|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260f3449-a2f4-4c25-9b0c-f38e85897c7f",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ## 2. Quick end-to-end example\n",
    "\n",
    " For this classification task, you will apply a simple [XGBoost](https://xgboost.readthedocs.io/en/stable/) (a gradient boosted trees framework) model to the June 2021 [New York City Taxi & Limousine Commission's Trip Record Data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page).\n",
    "\n",
    " The full dataset contains millions of samples of yellow cab rides, and the goal is to predict the tip amount.\n",
    "\n",
    " **Dataset features**\n",
    " * **`passenger_count`**\n",
    "     * Float (whole number) representing number of passengers.\n",
    " * **`trip_distance`**\n",
    "     * Float representing trip distance in miles.\n",
    " * **`fare_amount`**\n",
    "     * Float representing total price including tax, tip, fees, etc.\n",
    " * **`tolls_amount`**\n",
    "     * Float representing the total paid on tolls if any.\n",
    "\n",
    " **Target**\n",
    " * **`trip_amount`**\n",
    "     * Float representing the total paid as tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d220f-5b31-4e11-84fd-9e57c67e975d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.1 Vanilla XGboost code\n",
    "\n",
    " Let's start with the vanilla XGBoost code to predict the tip amount for a NYC taxi cab data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce97e98-e6f6-4709-8989-60ae8835d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "features = [\n",
    "    \"passenger_count\", \n",
    "    \"trip_distance\",\n",
    "    \"fare_amount\",\n",
    "    \"tolls_amount\",\n",
    "]\n",
    "\n",
    "label_column = \"tip_amount\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b630561-2de8-4d7d-aa2a-93b712cf5682",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Define a function to load the data and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13966177-46b4-4e0c-8ee6-1f338794bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# def load_data():\n",
    "#     path = \"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2021-03.parquet\"\n",
    "#     df = pd.read_parquet(path, columns=features + [label_column])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         df[features], df[label_column], test_size=0.2, random_state=42\n",
    "#     )\n",
    "#     dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "#     dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "#     return dtrain, dtest\n",
    "def load_data():\n",
    "    path = \"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2021-03.parquet\"\n",
    "    df = pd.read_parquet(\n",
    "        path,\n",
    "        columns=features + [label_column],\n",
    "        storage_options={\"anon\": True}\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[features], df[label_column], test_size=0.2, random_state=42\n",
    "    )\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dtest  = xgboost.DMatrix(X_test, label=y_test)\n",
    "    return dtrain, dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9880754-ae3e-41ef-80ef-0dbba07f552d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Define a function to run `xgboost.train` given some hyperparameter dictionary `params`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9910c1-0182-4832-beef-462282fe8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "storage_folder = \"/Users/phil/Documents/GITHUB/any_scale_academy/INTRO_RAY/data/01_Intro_Ray_AI_Libs_Overview/\" # Modify this path to your local folder if it runs on your local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e14f39-853b-4d26-a7b4-4105c259ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:2.18114\n",
      "[1]\teval-rmse:2.13805\n",
      "[2]\teval-rmse:2.10221\n",
      "[3]\teval-rmse:2.07294\n",
      "[4]\teval-rmse:2.04855\n",
      "[5]\teval-rmse:2.02852\n",
      "[6]\teval-rmse:2.01225\n",
      "[7]\teval-rmse:1.99868\n",
      "[8]\teval-rmse:1.98771\n",
      "[9]\teval-rmse:1.97872\n",
      "OrderedDict([('rmse', [2.18113709207776, 2.138052274494217, 2.1022143627953036, 2.072936825276888, 2.0485457212693987, 2.028522863406997, 2.0122461934067273, 1.99868078532301, 1.9877117047436585, 1.9787180742813582])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval-rmse': 1.9787180742813582}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "from pathlib import Path\n",
    "model_path = Path(storage_folder) / \"model.ubj\"\n",
    "\n",
    "def my_xgboost_func(params):    \n",
    "    evals_result = {}\n",
    "    dtrain, dtest = load_data()\n",
    "    bst = xgboost.train(\n",
    "        params, \n",
    "        dtrain, \n",
    "        num_boost_round=10, \n",
    "        evals=[(dtest, \"eval\")], \n",
    "        evals_result=evals_result,\n",
    "    )\n",
    "    # Use Path\n",
    "    bst.save_model(model_path)\n",
    "    print(f\"{evals_result['eval']}\")\n",
    "    return {\"eval-rmse\": evals_result[\"eval\"][\"rmse\"][-1]}\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"max_depth\": 6,\n",
    "    \"eta\": 0.1,\n",
    "}\n",
    "my_xgboost_func(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734b16a8-5560-4262-af74-a299c45dac86",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.2 Hyperparameter tuning with Ray Tune\n",
    "\n",
    " Let's use Ray Tune to run distributed hyperparameter tuning for the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a89ce-a187-4c82-9224-fb4842031fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-12-10 14:45:47</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:14.10        </td></tr>\n",
       "<tr><td>Memory:      </td><td>22.6/32.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/10 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">      eta</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  eval-rmse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>my_xgboost_func_ef28a_00000</td><td>TERMINATED</td><td>127.0.0.1:72583</td><td style=\"text-align: right;\">0.18427  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.54033</td><td style=\"text-align: right;\">    1.94223</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00001</td><td>TERMINATED</td><td>127.0.0.1:72580</td><td style=\"text-align: right;\">0.0251196</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.58364</td><td style=\"text-align: right;\">    2.12233</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00002</td><td>TERMINATED</td><td>127.0.0.1:72585</td><td style=\"text-align: right;\">0.0842778</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.42419</td><td style=\"text-align: right;\">    1.99422</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00003</td><td>TERMINATED</td><td>127.0.0.1:72584</td><td style=\"text-align: right;\">0.125585 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.99442</td><td style=\"text-align: right;\">    1.96126</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00004</td><td>TERMINATED</td><td>127.0.0.1:72586</td><td style=\"text-align: right;\">0.0439054</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.00385</td><td style=\"text-align: right;\">    2.066  </td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00005</td><td>TERMINATED</td><td>127.0.0.1:72581</td><td style=\"text-align: right;\">0.167708 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.78896</td><td style=\"text-align: right;\">    1.94573</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00006</td><td>TERMINATED</td><td>127.0.0.1:72587</td><td style=\"text-align: right;\">0.21994  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.11836</td><td style=\"text-align: right;\">    1.93804</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00007</td><td>TERMINATED</td><td>127.0.0.1:72582</td><td style=\"text-align: right;\">0.222276 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3.93908</td><td style=\"text-align: right;\">    1.93806</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00008</td><td>TERMINATED</td><td>127.0.0.1:72579</td><td style=\"text-align: right;\">0.270253 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.27694</td><td style=\"text-align: right;\">    1.93537</td></tr>\n",
       "<tr><td>my_xgboost_func_ef28a_00009</td><td>TERMINATED</td><td>127.0.0.1:72588</td><td style=\"text-align: right;\">0.0175397</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         6.75479</td><td style=\"text-align: right;\">    2.15092</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [0]\teval-rmse:2.12367\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [0]\teval-rmse:2.16855\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [1]\teval-rmse:2.05393\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [2]\teval-rmse:2.01048\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [1]\teval-rmse:2.11772\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [2]\teval-rmse:2.07765\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [3]\teval-rmse:1.98287\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [3]\teval-rmse:2.04667\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [4]\teval-rmse:1.96573\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [5]\teval-rmse:1.95506\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [4]\teval-rmse:2.02234\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [5]\teval-rmse:2.00350\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [6]\teval-rmse:1.94800\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [7]\teval-rmse:1.94348\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [6]\teval-rmse:1.98867\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [8]\teval-rmse:1.94036\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [7]\teval-rmse:1.97722\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [8]\teval-rmse:1.96826\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m [9]\teval-rmse:1.93806\n",
      "\u001b[36m(my_xgboost_func pid=72582)\u001b[0m OrderedDict([('rmse', [2.1236666493211453, 2.053928610380313, 2.010477232748054, 1.9828728363896975, 1.9657318770056553, 1.9550636423556937, 1.9479956352447492, 1.9434778174912672, 1.9403594069094314, 1.9380616577204626])])\n",
      "\u001b[36m(my_xgboost_func pid=72584)\u001b[0m [9]\teval-rmse:1.96126\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [0]\teval-rmse:2.12470\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [1]\teval-rmse:2.05524\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [2]\teval-rmse:2.01171\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [3]\teval-rmse:1.98393\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [4]\teval-rmse:1.96655\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [5]\teval-rmse:1.95570\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [6]\teval-rmse:1.94852\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [0]\teval-rmse:2.21961\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [1]\teval-rmse:2.20675\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [7]\teval-rmse:1.94390\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [8]\teval-rmse:1.94020\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [2]\teval-rmse:2.19447\n",
      "\u001b[36m(my_xgboost_func pid=72587)\u001b[0m [9]\teval-rmse:1.93804\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [0]\teval-rmse:2.14847\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [1]\teval-rmse:2.08714\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [3]\teval-rmse:2.18272\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [4]\teval-rmse:2.17151\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [2]\teval-rmse:2.04385\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [5]\teval-rmse:2.16079\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [3]\teval-rmse:2.01282\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [4]\teval-rmse:1.99108\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [6]\teval-rmse:2.15051\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [7]\teval-rmse:2.14066\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [5]\teval-rmse:1.97508\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [0]\teval-rmse:2.22364\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [1]\teval-rmse:2.21451\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [8]\teval-rmse:2.13126\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [6]\teval-rmse:1.96391\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [7]\teval-rmse:1.95594\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [2]\teval-rmse:2.20567\n",
      "\u001b[36m(my_xgboost_func pid=72580)\u001b[0m [9]\teval-rmse:2.12233\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [8]\teval-rmse:1.95027\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [3]\teval-rmse:2.19710\n",
      "\u001b[36m(my_xgboost_func pid=72581)\u001b[0m [9]\teval-rmse:1.94573\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [4]\teval-rmse:2.18880\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [5]\teval-rmse:2.18074\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [6]\teval-rmse:2.17292\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [7]\teval-rmse:2.16537\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [8]\teval-rmse:2.15803\n",
      "\u001b[36m(my_xgboost_func pid=72588)\u001b[0m [9]\teval-rmse:2.15092\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [0]\teval-rmse:2.20974\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [1]\teval-rmse:2.18820\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [2]\teval-rmse:2.16831\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [3]\teval-rmse:2.14991\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [4]\teval-rmse:2.13292\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [0]\teval-rmse:2.18902\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [1]\teval-rmse:2.15129\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [5]\teval-rmse:2.11722\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [6]\teval-rmse:2.10272\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [0]\teval-rmse:2.10303\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [1]\teval-rmse:2.02997\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [0]\teval-rmse:2.14079\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [2]\teval-rmse:2.11904\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [7]\teval-rmse:2.08952\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [2]\teval-rmse:1.98893\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [1]\teval-rmse:2.07631\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [3]\teval-rmse:2.09158\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [4]\teval-rmse:2.06834\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [8]\teval-rmse:2.07728\n",
      "\u001b[36m(my_xgboost_func pid=72586)\u001b[0m [9]\teval-rmse:2.06600\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [3]\teval-rmse:1.96626\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [4]\teval-rmse:1.95296\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [2]\teval-rmse:2.03248\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [3]\teval-rmse:2.00224\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [5]\teval-rmse:2.04844\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [5]\teval-rmse:1.94544\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [4]\teval-rmse:1.98191\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [6]\teval-rmse:2.03146\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [6]\teval-rmse:1.94107\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [7]\teval-rmse:1.93858\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [5]\teval-rmse:1.96745\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [6]\teval-rmse:1.95732\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [7]\teval-rmse:2.01719\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [8]\teval-rmse:2.00471\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [8]\teval-rmse:1.93658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 14:45:47,488\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/phil/Documents/GITHUB/any_scale_academy/INTRO_RAY/data/01_Intro_Ray_AI_Libs_Overview/my_xgboost_func_2025-12-10_14-45-27' in 0.0075s.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [7]\teval-rmse:1.95042\n",
      "\u001b[36m(my_xgboost_func pid=72585)\u001b[0m [9]\teval-rmse:1.99422\n",
      "\u001b[36m(my_xgboost_func pid=72579)\u001b[0m [9]\teval-rmse:1.93537\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [8]\teval-rmse:1.94556\n",
      "\u001b[36m(my_xgboost_func pid=72583)\u001b[0m [9]\teval-rmse:1.94223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 14:45:47,491\tINFO tune.py:1041 -- Total run time: 15.16 seconds (14.09 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'tree_method': 'hist', 'max_depth': 6, 'eta': 0.2702531923080533}\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# tuner = ray.tune.Tuner(  # Create a tuner\n",
    "#     my_xgboost_func,  # Pass it the training function which Ray Tune calls Trainable.\n",
    "#     param_space={  # Pass it the parameter space to search over\n",
    "#         \"objective\": \"reg:squarederror\",\n",
    "#         \"eval_metric\": \"rmse\",\n",
    "#         \"tree_method\": \"hist\",\n",
    "#         \"max_depth\": 6,\n",
    "#         \"eta\": ray.tune.uniform(0.01, 0.3),\n",
    "#     },\n",
    "#     run_config=RunConfig(storage_path=storage_folder),\n",
    "#     tune_config=ray.tune.TuneConfig(  # Tell it which metric to tune\n",
    "#         metric=\"eval-rmse\",\n",
    "#         mode=\"min\",\n",
    "#         num_samples=10,\n",
    "#     ),\n",
    "# )\n",
    "\n",
    "\n",
    "tuner = ray.tune.Tuner(\n",
    "    my_xgboost_func,\n",
    "    param_space={\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"eval_metric\": \"rmse\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"max_depth\": 6,\n",
    "        \"eta\": ray.tune.uniform(0.01, 0.3),\n",
    "    },\n",
    "    tune_config=ray.tune.TuneConfig(\n",
    "        metric=\"eval-rmse\",\n",
    "        mode=\"min\",\n",
    "        num_samples=10,\n",
    "    ),\n",
    "    run_config=ray.tune.RunConfig( # note use the tune config \n",
    "        storage_path=storage_folder,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "results = tuner.fit()  # Run the tuning job\n",
    "print(results.get_best_result().config)  # Get back the best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36885e91-1d39-420f-8428-bff02b133ce6",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Here is a diagram that shows what Tune does:\n",
    "\n",
    " It is effectively scheduling many trials and returning the best performing one.\n",
    "\n",
    " <img src=\"https://bair.berkeley.edu/static/blog/tune/tune-arch-simple.png\" width=\"700px\" loading=\"lazy\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77311ba4-c237-40e9-a635-bbecd464cbab",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.3. Distributed training with Ray Train\n",
    "\n",
    " In case your training data is too large, your training might take a long time to complete.\n",
    "\n",
    " To speed it up, shard the dataset across training workers and perform distributed XGBoost training.\n",
    "\n",
    " Let's redefine `load_data` to now load a different slice of the data given the worker index/rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3030ee7d-66c8-454a-a945-e1e663d0ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# def load_data():\n",
    "#     # find out which training worker is running this code\n",
    "#     train_ctx = ray.train.get_context()\n",
    "#     worker_rank = train_ctx.get_world_rank()\n",
    "#     print(f\"Loading data for worker {worker_rank}...\")\n",
    "\n",
    "#     # build path based on training worker rank\n",
    "#     month = (worker_rank + 1) % 12\n",
    "#     year = 2021 + (worker_rank + 1) // 12\n",
    "#     path = f\"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_{year}-{month:02}.parquet\"\n",
    "\n",
    "#     # same as before\n",
    "#     df = pd.read_parquet(path, columns=features + [label_column])\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         df[features], df[label_column], test_size=0.2, random_state=42\n",
    "#     )\n",
    "#     dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "#     dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "#     return dtrain, dtest\n",
    "\n",
    "def load_data():\n",
    "    train_ctx = ray.train.get_context()\n",
    "    worker_rank = train_ctx.get_world_rank()\n",
    "    print(f\"Loading data for worker {worker_rank}...\")\n",
    "\n",
    "    month = (worker_rank + 1) % 12\n",
    "    year = 2021 + (worker_rank + 1) // 12\n",
    "    path = f\"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_{year}-{month:02}.parquet\"\n",
    "\n",
    "    df = pd.read_parquet(\n",
    "        path,\n",
    "        columns=features + [label_column],\n",
    "        storage_options={\"anon\": True}   # <-- required\n",
    "    )\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[features], df[label_column], test_size=0.2, random_state=42\n",
    "    )\n",
    "    dtrain = xgboost.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgboost.DMatrix(X_test, label=y_test)\n",
    "    return dtrain, dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155b47a-1e71-46b1-b490-c1eb721ff41b",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Now we can run distributed XGBoost training using Ray Train's XGBoostTrainer - similar trainers exist for other popular ML frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679bb85-be56-4df1-8520-ad2c8c28e8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainController pid=72620)\u001b[0m Attempting to start training worker group of size 2 with the following resources: [{'CPU': 1}] * 2\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m Started training worker group of size 2: \n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m - (ip=127.0.0.1, pid=72633) world_rank=0, local_rank=0, node_rank=0\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m - (ip=127.0.0.1, pid=72634) world_rank=1, local_rank=1, node_rank=0\n",
      "\u001b[36m(RayTrainWorker pid=72633)\u001b[0m [14:45:55] Task [xgboost.ray-rank=00000000]:14831c1751e6b686b383bb6301000000 got rank 0\n",
      "\u001b[36m(RayTrainWorker pid=72633)\u001b[0m Loading data for worker 0...\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [0]\teval-rmse:2.28346\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [1]\teval-rmse:2.25069\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [2]\teval-rmse:2.22460\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [3]\teval-rmse:2.20430\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [4]\teval-rmse:2.18836\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [5]\teval-rmse:2.17259\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [6]\teval-rmse:2.15961\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [7]\teval-rmse:2.14910\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [8]\teval-rmse:2.14038\n",
      "\u001b[36m(TrainController pid=72620)\u001b[0m [14:45:57] [9]\teval-rmse:2.13346\n",
      "\u001b[36m(RayTrainWorker pid=72633)\u001b[0m OrderedDict([('rmse', [np.float64(2.283455977036048), np.float64(2.2506874095991365), np.float64(2.2245956490092267), np.float64(2.204302370137811), np.float64(2.1883569504768654), np.float64(2.1725859682897077), np.float64(2.1596106275006597), np.float64(2.149095348540642), np.float64(2.140382007941743), np.float64(2.133460611893429)])])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics=None, checkpoint=None, error=None, path='/Users/phil/ray_results/ray_train_run-2025-12-10_14-45-47', metrics_dataframe=None, best_checkpoints=[], _storage_filesystem=<pyarrow._fs.LocalFileSystem object at 0x3e69c8630>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "trainer = RayTrainXGBoostTrainer(  # Create a trainer\n",
    "    my_xgboost_func,  # Pass it the training function\n",
    "    scaling_config=ray.train.ScalingConfig(\n",
    "        num_workers=2, use_gpu=False\n",
    "    ),  # Define how many training workers\n",
    "    train_loop_config=params,  # Pass it the hyperparameters\n",
    ")\n",
    "\n",
    "trainer.fit()  # Run the training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6599d8e-7941-4bf2-af88-463a95c4ecb7",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Here is a diagram that shows what Train does:\n",
    "\n",
    " A train controller will create training workers and execute the training function on each worker.\n",
    "\n",
    " Ray Train delegates the distributed training to the underlying XGBoost framework.\n",
    "\n",
    " <img src=\"https://docs.ray.io/en/latest/_images/overview.png\" width=\"700px\" loading=\"lazy\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c625f62-704e-403a-bda9-f7320768a32d",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.4 Serving an ensemble model with Ray Serve\n",
    "\n",
    " Ray Serve allows for distributed serving of models and complex inference pipelines.\n",
    "\n",
    " Here is a diagram showing how to deploy an ensemble model with Ray Serve:\n",
    "\n",
    " <img src=\"https://images.ctfassets.net/xjan103pcp94/3DJ7vVRxYIvcFO7JmIUMCx/77a45caa275ffa46f5135f4d6726dd4f/Figure_2_-_Fanout_and_ensemble.png\" width=\"700px\" loading=\"lazy\">\n",
    "\n",
    " Here is how the resulting code looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513cc99-985a-451c-822e-0e27242852a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING 2025-12-10 14:45:59,321 serve 72513 -- There are multiple deployments with the same name 'Model'. Renaming one to 'Model_1'.\n",
      "INFO 2025-12-10 14:46:02,108 serve 72513 -- Started Serve in namespace \"serve\".\n",
      "\u001b[36m(ProxyActor pid=72648)\u001b[0m INFO 2025-12-10 14:46:02,018 proxy 127.0.0.1 -- Proxy starting on node 066c79cb5eded2851576d4533c020db7a4a1bf5e0ce9db48ca869e4c (HTTP port: 8000).\n",
      "\u001b[36m(ProxyActor pid=72648)\u001b[0m INFO 2025-12-10 14:46:02,091 proxy 127.0.0.1 -- Got updated endpoints: {}.\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,155 controller 72646 -- Deploying new version of Deployment(name='Model', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,156 controller 72646 -- Deploying new version of Deployment(name='Model_1', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,157 controller 72646 -- Deploying new version of Deployment(name='Ensemble', app='default') (initial target replicas: 1).\n",
      "\u001b[36m(ProxyActor pid=72648)\u001b[0m INFO 2025-12-10 14:46:02,159 proxy 127.0.0.1 -- Got updated endpoints: {Deployment(name='Ensemble', app='default'): EndpointInfo(route='/ensemble', app_is_cross_language=False, route_patterns=None)}.\n",
      "\u001b[36m(ProxyActor pid=72648)\u001b[0m INFO 2025-12-10 14:46:02,172 proxy 127.0.0.1 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x1360781d0>.\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,260 controller 72646 -- Adding 1 replica to Deployment(name='Model', app='default').\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,261 controller 72646 -- Adding 1 replica to Deployment(name='Model_1', app='default').\n",
      "\u001b[36m(ServeController pid=72646)\u001b[0m INFO 2025-12-10 14:46:02,309 controller 72646 -- Adding 1 replica to Deployment(name='Ensemble', app='default').\n",
      "\u001b[36m(ProxyActor pid=72648)\u001b[0m INFO 2025-12-10 14:46:03,883 proxy 127.0.0.1 -- Got updated endpoints: {Deployment(name='Ensemble', app='default'): EndpointInfo(route='/ensemble', app_is_cross_language=False, route_patterns=['/docs', '/docs/oauth2-redirect', '/openapi.json', '/predict', '/redoc'])}.\n",
      "INFO 2025-12-10 14:46:05,264 serve 72513 -- Application 'default' is ready at http://127.0.0.1:8000/ensemble.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "app = fastapi.FastAPI()\n",
    "\n",
    "class Payload(BaseModel):\n",
    "    passenger_count: int\n",
    "    trip_distance: float\n",
    "    fare_amount: float\n",
    "    tolls_amount: float\n",
    "\n",
    "\n",
    "@ray.serve.deployment\n",
    "@ray.serve.ingress(app)\n",
    "class Ensemble:\n",
    "    def __init__(self, model1, model2):\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "\n",
    "    @app.post(\"/predict\")\n",
    "    async def predict(self, data: Payload) -> dict:\n",
    "        model1_prediction, model2_prediction = await asyncio.gather(\n",
    "            self.model1.predict.remote([data.model_dump()]),\n",
    "            self.model2.predict.remote([data.model_dump()]),\n",
    "        )\n",
    "        out = {\"prediction\": float(model1_prediction + model2_prediction) / 2}\n",
    "        return out\n",
    "\n",
    "\n",
    "@ray.serve.deployment\n",
    "class Model:\n",
    "    def __init__(self, path: str):\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(path)\n",
    "\n",
    "    def predict(self, data: list[dict]) -> list[float]:\n",
    "        # Make prediction\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(data))\n",
    "        model_prediction = self._model.predict(dmatrix)\n",
    "        return model_prediction\n",
    "\n",
    "\n",
    "# Run the deployment\n",
    "handle = ray.serve.run(\n",
    "    Ensemble.bind(\n",
    "        model1=Model.bind(model_path),\n",
    "        model2=Model.bind(model_path),\n",
    "    ),\n",
    "    route_prefix=\"/ensemble\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb0b6a-bf5e-4c6e-a0c8-bd65cc1f0e81",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Let's make an HTTP request to the Ray Serve instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673dc2bf-30de-4709-9f1a-161eee63bcd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:Model pid=72650)\u001b[0m /Users/phil/anaconda3/envs/ray-jupyter/lib/python3.11/site-packages/ray/serve/_private/replica.py:1662: UserWarning: Calling sync method 'predict' directly on the asyncio loop. In a future version, sync methods will be run in a threadpool by default. Ensure your sync methods are thread safe or keep the existing behavior by making them `async def`. Opt into the new behavior by setting RAY_SERVE_RUN_SYNC_IN_THREADPOOL=1.\n",
      "\u001b[36m(ServeReplica:default:Model pid=72650)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(ServeReplica:default:Model pid=72650)\u001b[0m INFO 2025-12-10 14:46:05,359 default_Model oujxjs6t 6ea1f8ec-f3a0-4536-ab99-6014dff54379 -- CALL predict OK 4.2ms\n",
      "\u001b[36m(ServeReplica:default:Model_1 pid=72649)\u001b[0m INFO 2025-12-10 14:46:05,359 default_Model_1 1ybsyodk 6ea1f8ec-f3a0-4536-ab99-6014dff54379 -- CALL predict OK 3.4ms\n",
      "\u001b[36m(ServeReplica:default:Ensemble pid=72651)\u001b[0m INFO 2025-12-10 14:46:05,319 default_Ensemble e8hf4j7g 6ea1f8ec-f3a0-4536-ab99-6014dff54379 -- Started <ray.serve._private.router.SharedRouterLongPollClient object at 0x15f3c7950>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': 2.0076115131378174}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "requests.post(\n",
    "    \"http://localhost:8000/ensemble/predict\",\n",
    "    json={  # Use json parameter instead of params\n",
    "        \"passenger_count\": 1,\n",
    "        \"trip_distance\": 2.5,\n",
    "        \"fare_amount\": 10.0,\n",
    "        \"tolls_amount\": 0.5,\n",
    "    },\n",
    ").json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1762b28-97a8-4de6-9c53-ebcd05758fe4",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.5 Batch inference with Ray Data\n",
    "\n",
    " Ray Data allows for distributed data processing through streaming execution across a heterogeneous cluster of CPUs and GPUs.\n",
    "\n",
    " This makes Ray Data ideal for workloads like compute-intensive data processing, data ingestion, and batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f238e4-036d-477e-98ef-a7500fcb8ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ServeReplica:default:Ensemble pid=72651)\u001b[0m <ipython-input-10-931dbd35f5bf>:24: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "\u001b[36m(ServeReplica:default:Ensemble pid=72651)\u001b[0m INFO 2025-12-10 14:46:05,396 default_Ensemble e8hf4j7g 6ea1f8ec-f3a0-4536-ab99-6014dff54379 -- POST /ensemble/predict 200 101.7ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f55388249f4ece97de306b7bfbd59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet dataset sampling 0:   0%|          | 0.00/1.00 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 14:46:08,895\tINFO parquet_datasource.py:728 -- Estimated parquet encoding ratio is 9.752.\n",
      "2025-12-10 14:46:08,896\tINFO parquet_datasource.py:788 -- Estimated parquet reader batch size at 883012 rows\n",
      "2025-12-10 14:46:08,896\tINFO parquet_datasource.py:788 -- Estimated parquet reader batch size at 883012 rows\n",
      "2025-12-10 14:46:10,124\tWARNING util.py:598 -- The argument ``concurrency`` is deprecated in Ray 2.51. Please specify argument ``compute`` instead. For more information, see https://docs.ray.io/en/master/data/transforming-data.html#stateful-transforms.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "class OfflinePredictor:\n",
    "    def __init__(self):\n",
    "        # Load expensive state\n",
    "        self._model = xgboost.Booster()\n",
    "        self._model.load_model(model_path)\n",
    "\n",
    "    def predict(self, data: list[dict]) -> list[float]:\n",
    "        # Make prediction in batch\n",
    "        dmatrix = xgboost.DMatrix(pd.DataFrame(data))\n",
    "        model_prediction = self._model.predict(dmatrix)\n",
    "        return model_prediction\n",
    "\n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        batch[\"predictions\"] = self.predict(batch)\n",
    "        return batch\n",
    "\n",
    "\n",
    "# # Apply the predictor to the validation dataset\n",
    "# prediction_pipeline = (\n",
    "#     ray.data.read_parquet(\n",
    "#         \"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2021-03.parquet\",\n",
    "#     )\n",
    "#     .select_columns(features)\n",
    "#     .map_batches(OfflinePredictor, concurrency=(2, 10))\n",
    "# )\n",
    "\n",
    "import s3fs\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "prediction_pipeline = (\n",
    "    ray.data.read_parquet(\n",
    "        \"s3://anyscale-public-materials/nyc-taxi-cab/yellow_tripdata_2021-03.parquet\",\n",
    "        filesystem=fs,       # <-- fsspec FS object\n",
    "    )\n",
    "    .select_columns(features)\n",
    "    .map_batches(OfflinePredictor, concurrency=(2, 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d8f72-50c2-4bd9-84bb-d44544814611",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " After defining the pipeline, we can execute it in a distributed manner by writing the output to a sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0778ac29-5b67-4e44-84c4-d57383a54cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 14:46:10,157\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_4_0\n",
      "2025-12-10 14:46:10,168\tINFO streaming_executor.py:174 -- Starting execution of Dataset dataset_4_0. Full logs are in /tmp/ray/session_2025-12-10_14-45-27_396825_72513/logs/ray-data\n",
      "2025-12-10 14:46:10,169\tINFO streaming_executor.py:175 -- Execution plan of Dataset dataset_4_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> ActorPoolMapOperator[MapBatches(OfflinePredictor)] -> TaskPoolMapOperator[Write]\n",
      "2025-12-10 14:46:10,204\tINFO streaming_executor.py:682 -- [dataset]: A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True` and `ray.data.DataContext.get_current().use_ray_tqdm = False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43bd84c4c4944d5fac81a6b8479214fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef45e030d4943cabb021b0a9281f5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- ReadParquet->SplitBlocks(100) 1: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28382846f4d343328b88a51b7f27e509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- MapBatches(OfflinePredictor) 2: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e452952380544b028042f84b42c343df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Write 3: 0.00 row [00:00, ? row/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-10 14:46:10,285\tWARNING resource_manager.py:136 -- ‚ö†Ô∏è  Ray's object store is configured to use only 11.9% of available memory (2.0GiB out of 16.8GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "2025-12-10 14:46:15,782\tINFO streaming_executor.py:300 -- ‚úîÔ∏è  Dataset dataset_4_0 execution finished in 5.61 seconds\n",
      "2025-12-10 14:46:16,005\tINFO dataset.py:5193 -- Data sink Parquet finished. 1925152 rows and 66.1MiB data written.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "prediction_pipeline.write_parquet(f\"{storage_folder}/xgboost_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314cab61-e7e1-475c-bf47-01861a6681fc",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " Let's inspect the produced predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d94997-7dbb-4c17-b034-7c5af25fe34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000000_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000001_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000002_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000003_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000004_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000005_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000006_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000007_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000008_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000009_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000010_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000011_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000012_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000013_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000014_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000015_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000016_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000017_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000018_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000019_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000020_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000021_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000022_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000023_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000024_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000025_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000026_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000027_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000028_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000029_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000030_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000031_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000032_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000033_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000034_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000035_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000036_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000037_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000038_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000039_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000040_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000041_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000042_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000043_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000044_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000045_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000046_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000047_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000048_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000049_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000050_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000051_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000052_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000053_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000054_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000055_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000056_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000057_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000058_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000059_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000060_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000061_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000062_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000063_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000064_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000065_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000066_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000067_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000068_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000069_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000070_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000071_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000072_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000073_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000074_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000075_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000076_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000077_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000078_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000079_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000080_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000081_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000082_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000083_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000084_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000085_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000086_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000087_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000088_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000089_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000090_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000091_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000092_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000093_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000094_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000095_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000096_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000097_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000098_000000-0.parquet\n",
      "2_5a868b9ca2d24c7f87bd5a45441926dc_000099_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000000_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000001_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000002_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000003_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000004_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000005_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000006_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000007_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000008_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000009_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000010_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000011_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000012_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000013_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000014_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000015_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000016_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000017_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000018_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000019_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000020_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000021_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000022_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000023_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000024_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000025_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000026_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000027_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000028_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000029_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000030_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000031_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000032_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000033_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000034_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000035_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000036_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000037_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000038_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000039_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000040_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000041_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000042_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000043_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000044_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000045_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000046_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000047_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000048_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000049_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000050_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000051_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000052_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000053_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000054_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000055_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000056_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000057_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000058_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000059_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000060_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000061_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000062_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000063_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000064_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000065_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000066_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000067_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000068_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000069_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000070_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000071_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000072_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000073_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000074_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000075_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000076_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000077_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000078_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000079_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000080_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000081_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000082_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000083_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000084_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000085_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000086_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000087_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000088_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000089_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000090_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000091_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000092_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000093_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000094_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000095_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000096_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000097_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000098_000000-0.parquet\n",
      "2_5f4cdfb5c2554e92b05f36b3dc4c4089_000099_000000-0.parquet\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "!ls {storage_folder}/xgboost_predictions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9b0c85-a412-496b-9d87-fe79a2d62fa9",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "\n",
    " ### 2.6 Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a8f0f-0f4c-45ca-9e9a-e6816db0c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Run this cell for file cleanup \n",
    "# !rm -rf {storage_folder}/xgboost_predictions/\n",
    "# !rm {model_path}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
